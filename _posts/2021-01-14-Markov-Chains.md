---
layout: post
title: "Markov Chains"
date: 2021-01-14
tags: Stochastic
image: https://images.unsplash.com/photo-1520359319979-f360d010d777
thumb: https://images.unsplash.com/photo-1520359319979-f360d010d777?ixid=MXwxMjA3fDB8MHxzZWFyY2h8NHx8Y2hhaW5zfGVufDB8fDB8&ixlib=rb-1.2.1&auto=format&fit=crop&w=500&q=60w=500&q=60
imagecredit: https://unsplash.com/@trhammerhead
type: article
---

Markov Chains are a stochastic (random) modelling process, which aids in validating designs of systems with multiple states. 

## [Background](https://en.wikipedia.org/wiki/Markov_chain)

A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time Markov chain (CTMC). It is named after the Russian mathematician Andrey Markov.

Markov chains have many applications as statistical models of real-world processes, such as studying cruise control systems in motor vehicles, queues or lines of customers arriving at an airport, currency exchange rates and animal population dynamics.

Markov processes are the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in Bayesian statistics, thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory and artificial intelligence.

The adjective Markovian is used to describe something that is related to a Markov process

*Note: The opposite of stochastic is deterministic.  A deterministic system will always provide a consistent result, and randomness will never influence the result.*

<div><iframe src="/examples/markov.html" frameborder="0" height="400px" style="width:100%;"></iframe></div>

[Acknowledgements](https://setosa.io/markov/index.html)